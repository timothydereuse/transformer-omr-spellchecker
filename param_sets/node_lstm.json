{
    "params_name": "NODE_LSTM_FINAL",
    "num_epochs": 151,
    "early_stopping_patience": 5,
    "num_examples_to_save": 10,
    "save_model_every": 4,
    "save_img_every": 2,
    "max_time_minutes": 560,

    "seq_length": 256,
    "padding_amt": 64,
    "lr": 0.0001,
    "batch_size": 512,
    "clip_gradient_norm": 0.5,
    "num_feats": 1,
    "dataset_proportion": 1.0,

    "dset_path": "processed_datasets/all_string_quartets_big_agnostic_bymeasure.h5",
    "dset_testing_path": "processed_datasets/supervised_omr_targets_big_bymeasure.h5",
    "error_model": "processed_datasets/quartet_omr_error_models_big_bymeasure.joblib",
    "saved_vocabulary": "data_management/vocab_big.txt",
    "error_gen_smoothing": 4,
    "simple_errors": false,
    "errors_parallel": 1,
    "simple_error_rate": 0.1,
    "target_recalls": [0.8, 0.9, 0.95, 0.99],

    "lstut_settings": {
        "num_feats": 1,
        "output_feats": 1,
        "lstm_layers": 2,
        "tf_layers": 0,
        "tf_heads": 1,
        "tf_depth": 0,
        "hidden_dim": 512,
        "ff_dim": 128,
        "dropout": 0.1,
        "positional_encoding": false
    },
    "scheduler_settings": {
        "factor": 0.25,
        "patience": 5,
        "threshold": 0.001,
        "verbose": true
    },
    "param_sweep": [
        {"batch_size": 128, "seq_length": 512},
        {"batch_size": 1024, "seq_length": 128},
        {"lr": 0.005}
    ]
}
